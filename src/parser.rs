/**
 * Copyright (c) 2022 Hemashushu <hippospark@gmail.com>, All rights reserved.
 *
 * This Source Code Form is subject to the terms of the Mozilla Public
 * License, v. 2.0. If a copy of the MPL was not distributed with this
 * file, You can obtain one at http://mozilla.org/MPL/2.0/.
 */
use crate::{
    ast::{
        BinaryExpression, Bit, BlockExpression, Boolean, Char, Complex, Ellipsis, Expression,
        Float, GeneralString, HashString, Identifier, Integer, Interval, List, Literal,
        NamedOperator, Node, PrefixIdentifier, Program, Range, Statement, Tuple, UnaryExpression,
    },
    error::Error,
    token::{Token, TokenDetail},
};

pub fn parse(source_token_details: &[TokenDetail]) -> Result<Node, Error> {
    let program = parse_program(source_token_details)?;
    Ok(Node::Program(program))
}

// Program
//  : StatementList
//  ;
//
// StatementList
//  : Statement
//  | StatementList NEW_LINE Statement
//  ;
fn parse_program(source_token_details: &[TokenDetail]) -> Result<Program, Error> {
    let mut token_details = source_token_details;
    let mut statements = Vec::<Statement>::new();

    loop {
        // æ¶ˆé™¤å‰å¯¼çš„ç©ºè¡Œ
        let post_new_lines = skip_new_lines(token_details);

        if post_new_lines.first() == None {
            break;
        }

        let (statement, post_parse_statement) = parse_statement(post_new_lines)?;
        statements.push(statement);

        // å†è§£æå‰©ä½™çš„ tokenï¼Œç›´åˆ°è§£æå®Œæ‰€æœ‰ token ä¸ºæ­¢
        token_details = post_parse_statement;
    }

    Ok(Program {
        body: statements,
        range: new_range(),
    })
}

// Statement
//  : FunctionDeclaration
//  | Expression
//  ;
fn parse_statement(
    source_token_details: &[TokenDetail],
) -> Result<(Statement, &[TokenDetail]), Error> {
    let first = &source_token_details[0];
    match first.token {
        Token::Function => {
            // å‡½æ•°å£°æ˜è¯­å¥
            parse_function_declaration(source_token_details)
        }
        _ => {
            // è¡¨è¾¾å¼è¯­å¥
            parse_expression_statement(source_token_details)
        }
    }
}

// * FunctionDeclaration
// *  : 'function' IDENTIFIER '(' OptionalFormalParameterList ')' BlockStatement
// *  ;
//
// * FormalParameterList
// *  : Identifier
// *  | FormalParameterList ',' Identifier
// *  ;

fn parse_function_declaration(
    source_token_details: &[TokenDetail],
) -> Result<(Statement, &[TokenDetail]), Error> {
    todo!()
}

// ExpressionStatement
//  : Expression NEW_LINE
//  | Expression EOF
//  ;
fn parse_expression_statement(
    source_token_details: &[TokenDetail],
) -> Result<(Statement, &[TokenDetail]), Error> {
    let (expression, rest) = parse_expression(source_token_details)?;

    // statement ä»¥ Token::NewLine æˆ–è€… EOF ç»“æŸï¼Œæ¶ˆè€—è¿™ä¸ªæ¢è¡Œç¬¦ï¼ˆå¦‚æœå­˜åœ¨çš„è¯ï¼‰
    consume_new_line_token_if_exists(rest)
        .map(|post_rest| (Statement::Expression(expression), post_rest))
}

// Expression
//  : BlockExpression
//  |
//  | LetExpression
//  | ForExpression
//  | BranchExpression
//  | MatchExpression
//  | IfExpression
//  | BinaryExpression
//  | UnaryExpression
//  | FunctionCallExpression
//  | MemberExpression
//  | ConstructorExpression
//  | Identifier
//  | PrefixIdentifier
//  | Ellipsis
//  | Interval
//  | List
//  | Tuple
//  | Map
//  | Literal
//  ;

fn parse_expression(
    source_token_details: &[TokenDetail],
) -> Result<(Expression, &[TokenDetail]), Error> {
    if let Some(first) = source_token_details.first() {
        match first.token {
            Token::Do => {
                // do è¡¨è¾¾å¼
                parse_do_expression(source_token_details)
            }
            Token::Join => {
                // join è¡¨è¾¾å¼
                parse_join_expression(source_token_details)
            }
            Token::Let => {
                // let è¡¨è¾¾å¼
                parse_let_expression(source_token_details)
            }
            Token::For => {
                // for è¡¨è¾¾å¼
                parse_for_expression(source_token_details)
            }
            Token::Each => {
                // each è¡¨è¾¾å¼
                parse_each_expression(source_token_details)
            }
            Token::Branch => {
                // branch è¡¨è¾¾å¼
                parse_branch_expression(source_token_details)
            }
            Token::Match => {
                // match è¡¨è¾¾å¼
                parse_match_expression(source_token_details)
            }
            Token::If => {
                // if è¡¨è¾¾å¼
                parse_if_expression(source_token_details)
            }
            _ => {
                // äºŒå…ƒè¿ç®—è¡¨è¾¾å¼çš„å¼€å§‹
                parse_pipe_expression(source_token_details)
            }
        }
    } else {
        Err(Error::ParserError("expected expression".to_string()))
    }
}

// BlockExpression
//  : 'do' BlockExpression
//  ;
fn parse_do_expression(
    source_token_details: &[TokenDetail],
) -> Result<(Expression, &[TokenDetail]), Error> {
    // è§£æ do è¡¨è¾¾å¼ `do {...}`ï¼Œdo è¡¨è¾¾å¼æ˜¯ä¸€ä¸ªæ˜¾å¼è¡¨è¾¾å¼å—

    // æ¶ˆé™¤ do
    let post_consume_token_do = consume_token(&Token::Do, source_token_details)?;

    // æ¶ˆé™¤æ¢è¡Œç¬¦
    // do å…³é”®å­—åé¢å…è®¸æ¢è¡Œ
    let post_consume_new_lines = skip_new_lines(post_consume_token_do);

    let (expressions, post_parse_expression_block) =
        continue_parse_expression_block(post_consume_new_lines)?;

    Ok((
        Expression::BlockExpression(BlockExpression {
            is_explicit: true,
            body: expressions,
            range: new_range(),
        }),
        post_parse_expression_block,
    ))
}

// BlockExpression
//  : '{' ExpressionList '}'
//  ;
//
// ExpressionList
//  : Expression
//  | ExpressionList NEW_LINE Expression
//  ;
fn continue_parse_expression_block(
    source_token_details: &[TokenDetail],
) -> Result<(Vec<Expression>, &[TokenDetail]), Error> {
    // è§£æè¡¨è¾¾å¼å— `{...}`ï¼ˆä¹Ÿå« `éš å¼ Do è¡¨è¾¾å¼`ï¼‰
    // æ³¨æ„è¡¨è¾¾å¼å—ä»…å­˜åœ¨æŸäº›å…³é”®å­—åé¢ï¼Œæ¯”å¦‚ `join`ã€`do` ç­‰ï¼Œè€Œä¸èƒ½å•ç‹¬å­˜åœ¨ï¼Œ
    // å½“ä¸€å¯¹èŠ±æ‹¬å·å•ç‹¬å­˜åœ¨æ—¶ï¼Œä¼šè¢«è§£æä¸º Mapã€‚
    let mut token_details = source_token_details;

    token_details = consume_token(&Token::LeftBrace, token_details)?;

    let mut expressions: Vec<Expression> = vec![];

    loop {
        // å·¦èŠ±æ‹¬å· '{' åé¢å…è®¸æ¢è¡Œ
        // è¡¨è¾¾å¼ä¹‹é—´ä¹Ÿæ˜¯ä»¥æ¢è¡Œåˆ†éš”
        let post_consume_new_lines = skip_new_lines(token_details);

        // è§£æè¡¨è¾¾å¼
        let (expression, post_parse_expression) = parse_expression(post_consume_new_lines)?;
        expressions.push(expression);

        token_details = post_parse_expression;

        if is_token_ignore_new_lines(&Token::RightBrace, post_parse_expression) {
            break;
        }
    }

    let post_consume_token_right_brace =
        consume_token_ignore_new_lines(&Token::RightBrace, token_details)?;

    Ok((expressions, post_consume_token_right_brace))
}

fn continue_parse_expression_block_or_single_expression(
    source_token_details: &[TokenDetail],
) -> Result<(Expression, &[TokenDetail]), Error> {
    // è§£æ `{...}` æˆ–è€… `...`
    // åœ¨è¯¸å¦‚ `if`ã€`then`ã€`else` ç­‰å…³é”®å­—åé¢ï¼Œå³å¯ä»¥æ˜¯å•ç‹¬ä¸€ä¸ªè¡¨è¾¾å¼ï¼Œ
    // ä¹Ÿå¯ä»¥æ˜¯ä¸€ä¸ªè¡¨è¾¾å¼å—ã€‚
    //
    // è§£æä¼˜å…ˆçº§ï¼š
    // 1. å¦‚æœå­˜åœ¨ `{...}`ï¼Œåˆ™è§£æä¸ºéš å¼è¡¨è¾¾å¼å—
    // 2. å¦åˆ™è§£æä¸ºæ™®é€šçš„è¡¨è¾¾å¼

    match source_token_details.first() {
        Some(first) => match first.token {
            Token::LeftBrace => {
                let (expressions, post_parse_expression_block) =
                    continue_parse_expression_block(source_token_details)?;

                Ok((
                    Expression::BlockExpression(BlockExpression {
                        is_explicit: false,
                        body: expressions,
                        range: new_range(),
                    }),
                    post_parse_expression_block,
                ))
            }
            _ => parse_expression(source_token_details),
        },
        None => Err(Error::ParserError(
            "expected an expression or an expression block".to_string(),
        )),
    }
}

fn parse_join_expression(
    source_token_details: &[TokenDetail],
) -> Result<(Expression, &[TokenDetail]), Error> {
    // join {...}
    todo!()
}

// * VariableStatementInit
// *  : 'let' VariableDeclarationList
// *  ;
//
// * VariableStatement
// *  : 'let' VariableDeclarationList ';'
// *  ;
//
// * VariableDeclarationList
// *  : VariableDeclaration
// *  | VariableDeclarationList ',' VariableDeclaration

// * VariableDeclaration
// *  : Identifier OptionalVariableInitializer
// *  ;
//
// * VariableInitializer
// *  : SIMPLE_ASSIGN AssignmentExpression
// *  ;

fn parse_let_expression(
    source_token_details: &[TokenDetail],
) -> Result<(Expression, &[TokenDetail]), Error> {
    // let left =/match right
    todo!()
}

// * ForStatement
// *  : 'for' '(' OptionalForStatementInit ';' OptionalExpression ';' OptionalExpression ')' Statement
// *  ;
//
// * ForStatementInit
// *  : VariableStatementInit
// *  | Expression
// *  ;

fn parse_for_expression(
    source_token_details: &[TokenDetail],
) -> Result<(Expression, &[TokenDetail]), Error> {
    // for let ... = ... {... next}
    todo!()
}

fn parse_each_expression(
    source_token_details: &[TokenDetail],
) -> Result<(Expression, &[TokenDetail]), Error> {
    // each let ... in ... {...}
    todo!()
}

fn parse_branch_expression(
    source_token_details: &[TokenDetail],
) -> Result<(Expression, &[TokenDetail]), Error> {
    // branch {...}
    todo!()
}

fn parse_match_expression(
    source_token_details: &[TokenDetail],
) -> Result<(Expression, &[TokenDetail]), Error> {
    // match ... {...}
    todo!()
}

// * IfStatement
// *  : 'if' '(' Expression ')' Statement
// *  | 'if' '(' Expression ')' Statement 'else' Statement
// *  ;

fn parse_if_expression(
    source_token_details: &[TokenDetail],
) -> Result<(Expression, &[TokenDetail]), Error> {
    // if ... then ... else ...
    todo!()
}

// è§£æ `ä»å·¦å‘å³` ç»“åˆçš„äºŒå…ƒè¿ç®—çš„é€šç”¨å‡½æ•°
//
// BinaryExpression
//  : NextExpression
//  | BinaryExpression OPERATOR NextExpression
//  ;
fn parse_binary_expression<'a>(
    operator_tokens: &[Token],
    next_parse_function: fn(&[TokenDetail]) -> Result<(Expression, &[TokenDetail]), Error>,
    source_token_details: &'a [TokenDetail],
) -> Result<(Expression, &'a [TokenDetail]), Error> {
    let mut token_details = source_token_details;

    let (mut left, post_parse_left_expression) = next_parse_function(token_details)?;
    token_details = post_parse_left_expression;

    loop {
        let next_token = match token_details.first() {
            Some(first) => &first.token,
            None => {
                break;
            }
        };

        let index = match operator_tokens.iter().position(|t| t == next_token) {
            Some(i) => i,
            None => {
                break;
            }
        };

        let operator_token = &operator_tokens[index];

        // æ¶ˆé™¤æ“ä½œç¬¦
        let post_consume_token_operator = consume_token(operator_token, token_details)?;

        // äºŒå…ƒè¿ç®—ç¬¦åé¢å…è®¸æ¢è¡Œ
        let post_consume_new_lines = skip_new_lines(post_consume_token_operator);

        let (right, post_parse_right_expression) = next_parse_function(post_consume_new_lines)?;

        let expression = Expression::BinaryExpression(BinaryExpression {
            operator: operator_token.clone(),
            left: Box::new(left),
            right: Box::new(right),
            range: new_range(),
        });

        left = expression;
        token_details = post_parse_right_expression;
    }

    Ok((left, token_details))
}

// è§£æ `ä»å³å‘å·¦` ç»“åˆçš„äºŒå…ƒè¿ç®—çš„é€šç”¨å‡½æ•°
//
// BinaryExpression
//  : NextExpression
//  | NextExpression OPERATOR Expression
//  ;
fn parse_right_2_left_binary_expression<'a>(
    operator_token: &Token,
    next_parse_function: fn(&[TokenDetail]) -> Result<(Expression, &[TokenDetail]), Error>,
    source_token_details: &'a [TokenDetail],
) -> Result<(Expression, &'a [TokenDetail]), Error> {
    let mut token_details = source_token_details;

    let (mut left, post_parse_left_expression) = next_parse_function(token_details)?;
    token_details = post_parse_left_expression;

    if is_token(operator_token, token_details) {
        // æ¶ˆé™¤æ“ä½œç¬¦
        let post_consume_token_operator = consume_token(operator_token, token_details)?;

        // äºŒå…ƒè¿ç®—ç¬¦åé¢å…è®¸æ¢è¡Œ
        let pose_consume_new_lines = skip_new_lines(post_consume_token_operator);

        let (right, post_parse_right_expression) = parse_expression(pose_consume_new_lines)?;

        let expression = Expression::BinaryExpression(BinaryExpression {
            operator: operator_token.clone(),
            left: Box::new(left),
            right: Box::new(right),
            range: new_range(),
        });

        left = expression;
        token_details = post_parse_right_expression;
    }

    Ok((left, token_details))
}

fn parse_pipe_expression(
    source_token_details: &[TokenDetail],
) -> Result<(Expression, &[TokenDetail]), Error> {
    // left | right
    parse_binary_expression(
        &vec![Token::Pipe],
        parse_logic_or_expression,
        source_token_details,
    )
}

fn parse_logic_or_expression(
    source_token_details: &[TokenDetail],
) -> Result<(Expression, &[TokenDetail]), Error> {
    // left || right
    parse_binary_expression(
        &vec![Token::LogicOr],
        parse_logic_and_expression,
        source_token_details,
    )
}

fn parse_logic_and_expression(
    source_token_details: &[TokenDetail],
) -> Result<(Expression, &[TokenDetail]), Error> {
    // left && right
    parse_binary_expression(
        &vec![Token::LogicAnd],
        parse_equality_expression,
        source_token_details,
    )
}

fn parse_equality_expression(
    source_token_details: &[TokenDetail],
) -> Result<(Expression, &[TokenDetail]), Error> {
    // left == right, left != right
    parse_binary_expression(
        &vec![Token::Equal, Token::NotEqual],
        parse_relational_expression,
        source_token_details,
    )
}

fn parse_relational_expression(
    source_token_details: &[TokenDetail],
) -> Result<(Expression, &[TokenDetail]), Error> {
    // left > right, left >= right, left < right, left <= right
    parse_binary_expression(
        &vec![
            Token::GreaterThan,
            Token::GreaterThanOrEqual,
            Token::LessThan,
            Token::LessThanOrEqual,
        ],
        parse_named_operator_expression,
        source_token_details,
    )
}

fn parse_named_operator_expression(
    source_token_details: &[TokenDetail],
) -> Result<(Expression, &[TokenDetail]), Error> {
    // left :bitOr: right
    //
    // æ³¨ï¼š
    // å‘½åæ“ä½œç¬¦æ— æ³•ä½¿ç”¨é€šç”¨çš„äºŒå…ƒè¿ç®—è§£æå‡½æ•° parse_binary_expression
    let mut token_details = source_token_details;

    let (mut left, post_parse_left_expression) = parse_concat_expression(token_details)?;
    token_details = post_parse_left_expression;

    if let Some(TokenDetail {
        token: named_operator_token @ Token::NamedOperator(_),
        ..
    }) = token_details.first()
    {
        // æ¶ˆé™¤æ“ä½œç¬¦
        let post_consume_token_operator = consume_token(named_operator_token, token_details)?;

        // äºŒå…ƒè¿ç®—ç¬¦åé¢å…è®¸æ¢è¡Œ
        let pose_consume_new_lines = skip_new_lines(post_consume_token_operator);

        let (right, post_parse_right_expression) = parse_concat_expression(pose_consume_new_lines)?;

        let expression = Expression::BinaryExpression(BinaryExpression {
            operator: named_operator_token.clone(),
            left: Box::new(left),
            right: Box::new(right),
            range: new_range(),
        });

        left = expression;
        token_details = post_parse_right_expression;
    }

    Ok((left, token_details))
}

fn parse_concat_expression(
    source_token_details: &[TokenDetail],
) -> Result<(Expression, &[TokenDetail]), Error> {
    // left ++ right
    parse_binary_expression(
        &vec![Token::Concat],
        parse_additive_expression,
        source_token_details,
    )
}

fn parse_additive_expression(
    source_token_details: &[TokenDetail],
) -> Result<(Expression, &[TokenDetail]), Error> {
    // left + right, left - right
    parse_binary_expression(
        &vec![Token::Plus, Token::Minus],
        parse_multiplicative_expression,
        source_token_details,
    )
}

fn parse_multiplicative_expression(
    source_token_details: &[TokenDetail],
) -> Result<(Expression, &[TokenDetail]), Error> {
    // left * right, left / right
    parse_binary_expression(
        &vec![Token::Asterisk, Token::Slash],
        parse_optional_or_expression,
        source_token_details,
    )
}

fn parse_optional_or_expression(
    source_token_details: &[TokenDetail],
) -> Result<(Expression, &[TokenDetail]), Error> {
    // left ?? right
    parse_binary_expression(
        &vec![Token::OptionalOr],
        parse_optional_and_expression,
        source_token_details,
    )
}

fn parse_optional_and_expression(
    source_token_details: &[TokenDetail],
) -> Result<(Expression, &[TokenDetail]), Error> {
    // left >> right
    parse_binary_expression(
        &vec![Token::OptionalAnd],
        parse_combine_expression,
        source_token_details,
    )
}

fn parse_combine_expression(
    source_token_details: &[TokenDetail],
) -> Result<(Expression, &[TokenDetail]), Error> {
    // left & right
    // ç»“åˆæ–¹å‘ï¼šä»å³å‘å·¦
    parse_right_2_left_binary_expression(
        &Token::Combine,
        parse_cast_expression,
        source_token_details,
    )
}

fn parse_cast_expression(
    source_token_details: &[TokenDetail],
) -> Result<(Expression, &[TokenDetail]), Error> {
    // ä¸€å…ƒè¿ç®—è¡¨è¾¾å¼ object^
    let (left, post_parse_expression) = parse_negative_expression(source_token_details)?;

    if is_token(&Token::Cast, post_parse_expression) {
        let post_consume_token_operator = consume_token(&Token::Cast, post_parse_expression)?;

        Ok((
            Expression::UnaryExpression(UnaryExpression {
                operator: Token::Cast,
                operand: Box::new(left),
                range: new_range(),
            }),
            post_consume_token_operator,
        ))
    } else {
        Ok((left, post_parse_expression))
    }
}

fn parse_negative_expression(
    source_token_details: &[TokenDetail],
) -> Result<(Expression, &[TokenDetail]), Error> {
    // ä¸€å…ƒè¿ç®—è¡¨è¾¾å¼ -object
    if is_token(&Token::Minus, source_token_details) {
        let post_consume_token_operator = consume_token(&Token::Cast, source_token_details)?;
        let (left, post_parse_expression) = parse_unwrap_expression(post_consume_token_operator)?;

        Ok((
            Expression::UnaryExpression(UnaryExpression {
                operator: Token::Minus,
                operand: Box::new(left),
                range: new_range(),
            }),
            post_parse_expression,
        ))
    } else {
        parse_unwrap_expression(source_token_details)
    }
}

fn parse_unwrap_expression(
    source_token_details: &[TokenDetail],
) -> Result<(Expression, &[TokenDetail]), Error> {
    // ä¸€å…ƒè¿ç®—è¡¨è¾¾å¼ object?
    let (left, post_parse_expression) = parse_function_call_expression(source_token_details)?;

    if is_token(&Token::Unwrap, post_parse_expression) {
        let post_consume_token_operator = consume_token(&Token::Unwrap, post_parse_expression)?;

        Ok((
            Expression::UnaryExpression(UnaryExpression {
                operator: Token::Unwrap,
                operand: Box::new(left),
                range: new_range(),
            }),
            post_consume_token_operator,
        ))
    } else {
        Ok((left, post_parse_expression))
    }
}

// * CallOrMemberExpression
// *  : MemberExpression
// *  | CallExpression
// *  ;
//
// * CallExpression
// *  : Callee Arguments
// *  ;
// *
// * Callee
// *  : MemberExpression
// *  | CallExpression

fn parse_function_call_expression(
    source_token_details: &[TokenDetail],
) -> Result<(Expression, &[TokenDetail]), Error> {
    // foo()
    // todo::
    parse_member_or_slice_expression(source_token_details)
}

// * MemberExpression
// *  : PrimaryExpression
// *  | MemberExpression '.' Identifier
// *  | MemberExpression '[' Expression ']'

fn parse_member_or_slice_expression(
    source_token_details: &[TokenDetail],
) -> Result<(Expression, &[TokenDetail]), Error> {
    // object.property, object["foo"]
    // todo::
    parse_constructor_expression(source_token_details)
}

// * ConstructorExpression
// *  : Identifier {...}
// *  ;

fn parse_constructor_expression(
    source_token_details: &[TokenDetail],
) -> Result<(Expression, &[TokenDetail]), Error> {
    // object {name: vale, ...}
    // todo::
    parse_primary_expression(source_token_details)
}

// PrimaryExpression
//  : List
//  | Tuple/Parenthesized
//  | Map
//  | Identifier
//  ;
fn parse_primary_expression(
    source_token_details: &[TokenDetail],
) -> Result<(Expression, &[TokenDetail]), Error> {
    match source_token_details.first() {
        Some(first) => match first.token {
            Token::Fn => todo!(),
            Token::Sign => todo!(),
            Token::Exclamation => {
                parse_prefix_identifier(source_token_details) // å‡½æ•°çš„å‰ç½®è°ƒç”¨
            }
            Token::Ellipsis => todo!(),
            Token::LeftParen => parse_tuple_or_parenthesized(source_token_details),
            Token::LeftBracket => parse_list(source_token_details),
            Token::LeftBrace => parse_map(source_token_details),
            Token::Identifier(_) => parse_identifier(source_token_details),
            _ => {
                let (literal, post_rest) = parse_literal(source_token_details)?;
                Ok((Expression::Literal(literal), post_rest))
            }
        },
        None => Err(Error::ParserError(
            "expected primary expression".to_string(),
        )),
    }
}

fn parse_prefix_identifier(
    source_token_details: &[TokenDetail],
) -> Result<(Expression, &[TokenDetail]), Error> {
    // prefix identifier
    let post_consume_token_exclamation = consume_token(&Token::Exclamation, source_token_details)?;

    let (identifier, post_continue_parse_identifier) =
        continue_parse_identifier(post_consume_token_exclamation)?;

    Ok((
        Expression::PrefixIdentifier(PrefixIdentifier {
            identifier: identifier,
            range: new_range(),
        }),
        post_continue_parse_identifier,
    ))
}

fn parse_identifier(
    source_token_details: &[TokenDetail],
) -> Result<(Expression, &[TokenDetail]), Error> {
    // identifier
    //
    // One::Two::Three::Name
    let (identifier, post_continue_parse_identifier) =
        continue_parse_identifier(source_token_details)?;

    Ok((
        Expression::Identifier(identifier),
        post_continue_parse_identifier,
    ))
}

fn continue_parse_identifier(
    source_token_details: &[TokenDetail],
) -> Result<(Identifier, &[TokenDetail]), Error> {
    // identifier
    //
    // e.g.
    // One::Two::Three::Name
    let mut token_details = source_token_details;
    let mut names: Vec<String> = vec![];

    if let Some((
        TokenDetail {
            token: Token::Identifier(name),
            ..
        },
        rest,
    )) = token_details.split_first()
    {
        // è·å–ç¬¬ä¸€ä¸ª identifier
        names.push(name.clone());
        token_details = rest;

        // è·å–å…¶ä½™çš„ identifier
        loop {
            token_details = match token_details.split_first() {
                Some((first, post_token_separator)) if first.token == Token::Separator => {
                    // æ£€æµ‹åˆ° namespace path åˆ†éš”ç¬¦ `::`
                    if let Some((
                        TokenDetail {
                            token: Token::Identifier(name),
                            ..
                        },
                        post_token_identifier,
                    )) = post_token_separator.split_first()
                    {
                        // æ£€æµ‹åˆ°ä¸€ä¸ª identifier
                        names.push(name.clone());
                        post_token_identifier
                    } else {
                        // åœ¨ namespace path åˆ†éš”ç¬¦ `::` åé¢å¿…é¡»æ˜¯ä¸€ä¸ª identifier
                        return Err(Error::ParserError("expected identifier".to_string()));
                    }
                }
                _ => {
                    break;
                }
            }
        }
    }

    if names.len() == 0 {
        Err(Error::ParserError("expected identifier".to_string()))
    } else {
        let len = names.len();
        Ok((
            Identifier {
                dirs: names[..len - 1].iter().map(|n| n.clone()).collect(),
                name: names[len - 1].clone(),
                generic_names: vec![],
                range: new_range(),
            },
            token_details,
        ))
    }
}

// Literal
//  : Integer
//  | Float
//  | Complex
//  | Bit
//  | Boolean
//  | Char
//  | GeneralString
//  | TemplateString
//  | HashString
//  | NamedOperator
//  ;

fn parse_literal(source_token_details: &[TokenDetail]) -> Result<(Literal, &[TokenDetail]), Error> {
    // literal
    match source_token_details.split_first() {
        Some((first, rest)) => match &first.token {
            Token::Integer(v) => match continue_parse_imaginary(rest) {
                // æ•´æ•°æˆ–å¤æ•°
                Ok((f, post_rest)) => Ok((
                    Literal::Complex(Complex {
                        real: *v as f64,
                        imaginary: f,
                        range: new_range(),
                    }),
                    post_rest,
                )),
                _ => Ok((
                    Literal::Integer(Integer {
                        value: *v,
                        range: new_range(),
                    }),
                    rest,
                )),
            },
            Token::Float(v) => match continue_parse_imaginary(rest) {
                // æµ®ç‚¹æ•°æˆ–å¤æ•°
                Ok((f, post_rest)) => Ok((
                    Literal::Complex(Complex {
                        real: *v,
                        imaginary: f,
                        range: new_range(),
                    }),
                    post_rest,
                )),
                _ => Ok((
                    Literal::Float(Float {
                        value: *v,
                        range: new_range(),
                    }),
                    rest,
                )),
            },
            Token::Imaginary(v) => {
                // åªæœ‰å•ç‹¬è™šéƒ¨çš„å¤æ•°
                Ok((
                    Literal::Complex(Complex {
                        real: 0f64,
                        imaginary: *v,
                        range: new_range(),
                    }),
                    rest,
                ))
            }
            Token::Bit(width, bytes) => Ok((
                Literal::Bit(Bit {
                    width: *width,
                    bytes: bytes.clone(),
                    range: new_range(),
                }),
                rest,
            )),
            Token::Boolean(v) => Ok((
                Literal::Boolean(Boolean {
                    value: *v,
                    range: new_range(),
                }),
                rest,
            )),
            Token::Char(v) => Ok((
                Literal::Char(Char {
                    value: *v,
                    range: new_range(),
                }),
                rest,
            )),
            Token::GeneralString(v) => Ok((
                Literal::GeneralString(GeneralString {
                    value: v.clone(),
                    range: new_range(),
                }),
                rest,
            )),
            Token::TemplateString(v) => {
                // todo::
                // è¿™é‡Œéœ€è¦é‡æ–° tokenize æ¨¡æ¿å­—ç¬¦ä¸²é‡Œé¢çš„å ä½ç¬¦è¡¨è¾¾å¼ï¼Œ
                // ç„¶åé‡æ–°è§£æè¿™äº›è¡¨è¾¾å¼
                todo!()
            }
            Token::HashString(v) => Ok((
                Literal::HashString(HashString {
                    value: v.clone(),
                    range: new_range(),
                }),
                rest,
            )),
            Token::NamedOperator(v) => Ok((
                Literal::NamedOperator(NamedOperator {
                    value: v.clone(),
                    range: new_range(),
                }),
                rest,
            )),
            _ => Err(Error::ParserError("unexpected literal".to_string())),
        },
        None => Err(Error::ParserError("expected literal".to_string())),
    }
}

fn parse_list(source_token_details: &[TokenDetail]) -> Result<(Expression, &[TokenDetail]), Error> {
    // list
    //
    // e.g.
    // [123, 345, 567,]
    // [1..10]
    // [1..=9]
    // [1,3..10]

    let mut token_details = source_token_details;

    let mut expressions: Vec<Expression> = vec![];
    let mut is_expected_end = false;

    token_details = consume_token(&Token::LeftBracket, token_details)?; // æ¶ˆé™¤å·¦ä¸­æ‹¬å·
    token_details = skip_new_lines(token_details); // å·¦ä¸­æ‹¬å·åé¢å…è®¸æ¢è¡Œ

    loop {
        token_details = match token_details.first() {
            Some(first) => {
                if let TokenDetail {
                    token: Token::RightBracket,
                    ..
                } = first
                {
                    // æ‰¾åˆ°å³ä¸­æ‹¬å·ï¼Œé€€å‡ºå¾ªç¯
                    break;
                } else {
                    if is_expected_end {
                        // å½“å‰åªå…è®¸å³ä¸­æ‹¬å·
                        return Err(Error::ParserError(
                            "expected the right bracket symbol \"]\"".to_string(),
                        ));
                    } else {
                        // å…ˆæ£€æŸ¥æ˜¯å¦ `å±•å¼€å¼`
                        if let TokenDetail {
                            token: Token::Ellipsis,
                            ..
                        } = first
                        {
                            // å½“å‰æ˜¯ `å±•å¼€å¼`
                            let (ellipsis, post_rest) = continue_parse_ellipsis(token_details)?;
                            expressions.push(Expression::Ellipsis(ellipsis));
                            is_expected_end = true; // è®¾ç½®æ ‡è®°ï¼Œ`å±•å¼€å¼` åé¢åªèƒ½å…è®¸å³ä¸­æ‹¬å·

                            // æ¶ˆé™¤é€—å·
                            let post_consume_comma = if is_token(&Token::Comma, post_rest) {
                                consume_token(&Token::Comma, post_rest)?
                            } else {
                                post_rest
                            };

                            // æ¶ˆé™¤ç©ºè¡Œ
                            let post_consume_new_lines = skip_new_lines(post_consume_comma);
                            post_consume_new_lines
                        } else {
                            // è§£ææ™®é€šè¡¨è¾¾å¼
                            let (expression, post_rest) = parse_expression(token_details)?;

                            let post_check_interval = if is_token(&Token::Interval, post_rest)
                                || is_token(&Token::IntervalInclusive, post_rest)
                            {
                                // å½“å‰æ˜¯èŒƒå›´è¡¨è¾¾å¼
                                let (
                                    is_inclusive,
                                    optional_to_expression,
                                    post_continue_parse_interval,
                                ) = continue_parse_interval(post_rest)?;

                                let interval_expression = Expression::Interval(Interval {
                                    is_inclusive,
                                    from: Box::new(expression),
                                    to: match optional_to_expression {
                                        Some(end_expression) => Some(Box::new(end_expression)),
                                        None => None,
                                    },
                                    range: new_range(),
                                });

                                is_expected_end = true; // è®¾ç½®æ ‡è®°ï¼Œ`èŒƒå›´è¡¨è¾¾å¼` åé¢åªèƒ½å…è®¸å³ä¸­æ‹¬å·

                                expressions.push(interval_expression);
                                post_continue_parse_interval
                            } else {
                                // å½“å‰æ˜¯æ™®é€šè¡¨è¾¾å¼
                                expressions.push(expression);
                                post_rest
                            };

                            // æ¶ˆé™¤é€—å·
                            let post_consume_comma = if is_token(&Token::Comma, post_check_interval)
                            {
                                consume_token(&Token::Comma, post_check_interval)?
                            } else {
                                post_check_interval
                            };

                            // æ¶ˆé™¤ç©ºè¡Œ
                            let post_consume_new_lines = skip_new_lines(post_consume_comma);
                            post_consume_new_lines
                        }
                    }
                }
            }
            None => {
                return Err(Error::ParserError(
                    "expected the right paren symbol \")\"".to_string(),
                ))
            }
        }
    }

    // æ¶ˆé™¤å³æ‹¬å·
    token_details = consume_token(&Token::RightBracket, token_details)?;

    Ok((
        Expression::List(List {
            elements: expressions,
            range: new_range(),
        }),
        token_details,
    ))
}

fn parse_tuple_or_parenthesized(
    source_token_details: &[TokenDetail],
) -> Result<(Expression, &[TokenDetail]), Error> {
    // tuple or parenthesized
    //
    // e.g.
    //
    // tuple:
    //
    // ()
    // (one,)
    // (one, two, )
    // (one, two, ...)
    // (one, two, ...rest)
    //
    // parenthesized:
    //
    // (expression)

    let mut token_details = source_token_details;

    let mut expressions: Vec<Expression> = vec![];
    let mut is_tuple = false;
    let mut is_expected_end = false;

    token_details = consume_token(&Token::LeftParen, token_details)?; // æ¶ˆé™¤å·¦æ‹¬å·
    token_details = skip_new_lines(token_details); // å·¦æ‹¬å·åé¢å…è®¸æ¢è¡Œ

    loop {
        token_details = match token_details.first() {
            Some(first) => {
                if let TokenDetail {
                    token: Token::RightParen,
                    ..
                } = first
                {
                    // æ‰¾åˆ°å³æ‹¬å·ï¼Œé€€å‡ºå¾ªç¯
                    break;
                } else {
                    if is_expected_end {
                        // å½“å‰åªå…è®¸å³æ‹¬å·
                        return Err(Error::ParserError(
                            "expected the right paren symbol \")\"".to_string(),
                        ));
                    } else {
                        // å…ˆæ£€æŸ¥æ˜¯å¦ `å±•å¼€å¼`
                        if let TokenDetail {
                            token: Token::Ellipsis,
                            ..
                        } = first
                        {
                            // å½“å‰æ˜¯ `å±•å¼€å¼`
                            let (ellipsis, post_rest) = continue_parse_ellipsis(token_details)?;
                            expressions.push(Expression::Ellipsis(ellipsis));
                            is_expected_end = true; // è®¾ç½®æ ‡è®°ï¼Œ`å±•å¼€å¼` åé¢åªèƒ½å…è®¸å³æ‹¬å·

                            // æ¶ˆé™¤é€—å·
                            let post_consume_comma = if is_token(&Token::Comma, post_rest) {
                                consume_token(&Token::Comma, post_rest)?
                            } else {
                                post_rest
                            };

                            // æ¶ˆé™¤ç©ºè¡Œ
                            let post_consume_new_lines = skip_new_lines(post_consume_comma);
                            post_consume_new_lines
                        } else {
                            // å½“å‰æ˜¯æ™®é€šè¡¨è¾¾å¼
                            let (expression, post_rest) = parse_expression(token_details)?;
                            expressions.push(expression);

                            // æ¶ˆé™¤é€—å·
                            let post_consume_comma = if is_token(&Token::Comma, post_rest) {
                                is_tuple = true;
                                consume_token(&Token::Comma, post_rest)?
                            } else {
                                post_rest
                            };

                            // æ¶ˆé™¤ç©ºè¡Œ
                            let post_consume_new_lines = skip_new_lines(post_consume_comma);
                            post_consume_new_lines
                        }
                    }
                }
            }
            None => {
                return Err(Error::ParserError(
                    "expected the right paren symbol \")\"".to_string(),
                ))
            }
        }
    }

    // æ¶ˆé™¤å³æ‹¬å·
    token_details = consume_token(&Token::RightParen, token_details)?;

    if expressions.len() == 0 {
        // ç©ºå…ƒç»„
        Ok((
            Expression::Tuple(Tuple {
                elements: vec![],
                range: new_range(),
            }),
            token_details,
        ))
    } else {
        if is_tuple {
            // å…ƒç»„
            Ok((
                Expression::Tuple(Tuple {
                    elements: expressions,
                    range: new_range(),
                }),
                token_details,
            ))
        } else {
            // æ™®é€šçš„æ‹¬å·è¡¨è¾¾å¼
            Ok((expressions[0].clone(), token_details))
        }
    }
}

fn continue_parse_ellipsis(
    source_token_details: &[TokenDetail],
) -> Result<(Ellipsis, &[TokenDetail]), Error> {
    // ...
    // ..._
    // ...abc
    // ^  ^--- identifier
    // |------ ellipsisï¼Œå½“å‰å¤„äºè¿™ä¸ª token

    // æ¶ˆé™¤çœç•¥å· `...`
    let post_consume_token_ellipsis = consume_token(&Token::Ellipsis, source_token_details)?;

    if let Some((
        TokenDetail {
            token: Token::Identifier(name),
            ..
        },
        post_consume_token_identifier,
    )) = post_consume_token_ellipsis.split_first()
    {
        // çœç•¥å· `...` åé¢æœ‰æ ‡è¯†ç¬¦
        Ok((
            Ellipsis {
                name: Some(name.clone()),
                range: new_range(),
            },
            post_consume_token_identifier,
        ))
    } else {
        // çœç•¥å· `...` åé¢æ— æ ‡è¯†ç¬¦
        Ok((
            Ellipsis {
                name: None,
                range: new_range(),
            },
            post_consume_token_ellipsis,
        ))
    }
}

// è§£æ `èŒƒå›´è¡¨è¾¾å¼`
// è¿”å› (`to` æ˜¯å¦é—­åŒºé—´, `to` è¡¨è¾¾å¼, å‰©ä½™çš„ token)
fn continue_parse_interval(
    source_token_details: &[TokenDetail],
) -> Result<(bool, Option<Expression>, &[TokenDetail]), Error> {
    // exp1..=
    // exp1..=exp2
    // exp1..
    // exp1..exp2
    // ^   ^ ^--- expression (å¯é€‰çš„)
    // |   |----- interval å½“å‰å¤„äºè¿™ä¸ª token
    // |--------- expression

    let is_inclusive = is_token(&Token::IntervalInclusive, source_token_details);
    let operator_token = if is_inclusive {
        Token::IntervalInclusive
    } else {
        Token::Interval
    };

    // æ¶ˆé™¤èŒƒå›´ç¬¦å· ".."
    let post_consume_token_interval = consume_token(&operator_token, source_token_details)?;

    // èŒƒå›´ç¬¦å· ".." åé¢å…è®¸æ¢è¡Œ
    let post_new_lines = skip_new_lines(post_consume_token_interval);

    match post_new_lines.first() {
        Some(TokenDetail { token, .. })
            if (*token == Token::Comma || *token == Token::RightBracket) =>
        {
            // é‡åˆ°äº†é€—å·æˆ–è€…å³ä¸­æ‹¬å·
            if is_inclusive {
                // å¯¹äºé—­åŒºé—´çš„èŒƒå›´è¡¨è¾¾å¼ï¼Œ`to` éƒ¨åˆ†æ˜¯ä¸èƒ½çœç•¥çš„ã€‚
                Err(Error::ParserError(
                    "expected inclusive range end".to_string(),
                ))
            } else {
                // å½“å‰èŒƒå›´è¡¨è¾¾å¼ç¼ºçœäº† `to` éƒ¨åˆ†ã€‚
                Ok((is_inclusive, None, post_new_lines))
            }
        }
        _ => {
            // è§£æ `to` éƒ¨åˆ†è¡¨è¾¾å¼
            let (to_expression, post_parse_to_expression) = parse_expression(post_new_lines)?;
            Ok((is_inclusive, Some(to_expression), post_parse_to_expression))
        }
    }
}

fn parse_map(source_token_details: &[TokenDetail]) -> Result<(Expression, &[TokenDetail]), Error> {
    // map
    //
    // e.g.
    // {name: value, name, expression, ...}
    todo!()
}

// è·³è¿‡ç©ºç™½çš„è¡Œï¼Œåœ¨ lexer é‡Œäº§ç”Ÿçš„ Token åºåˆ—å½“ä¸­ï¼Œæœ‰å¯èƒ½å­˜åœ¨å¤šè¡Œè¿ç»­çš„ç©ºè¡Œï¼Œ
// åœ¨è§£æä¸€ä¸ªstatement ä¹‹å‰ï¼Œæˆ–è€… expression ä¹‹é—´ï¼Œéœ€è¦æ¶ˆé™¤è¿™äº›ç©ºç™½çš„å‰å¯¼ç©ºè¡Œ
fn skip_new_lines(source_token_details: &[TokenDetail]) -> &[TokenDetail] {
    let mut token_details = source_token_details;

    loop {
        token_details = match token_details.split_first() {
            Some((first, rest)) if first.token == Token::NewLine => rest,
            _ => {
                break;
            }
        }
    }

    token_details
}

fn is_token(expected: &Token, source_token_details: &[TokenDetail]) -> bool {
    match source_token_details.first() {
        Some(first) if &first.token == expected => true,
        _ => false,
    }
}

fn is_token_ignore_new_lines(expected: &Token, source_token_details: &[TokenDetail]) -> bool {
    let token_details = skip_new_lines(source_token_details);
    is_token(expected, token_details)
}

fn continue_parse_imaginary(
    source_token_details: &[TokenDetail],
) -> Result<(f64, &[TokenDetail]), ()> {
    match source_token_details.split_first() {
        Some((first, rest)) if first.token == Token::Plus => match rest.split_first() {
            Some((
                TokenDetail {
                    token: Token::Imaginary(f),
                    ..
                },
                post_rest,
            )) => Ok((*f, post_rest)),
            _ => Err(()),
        },
        _ => Err(()),
    }
}

fn consume_token<'a>(
    expected: &Token,
    source_token_details: &'a [TokenDetail],
) -> Result<&'a [TokenDetail], Error> {
    match source_token_details.split_first() {
        Some((first, rest)) if &first.token == expected => Ok(rest),
        _ => Err(Error::ParserError(format!(
            "expected the specified symbol \"{}\"",
            expected
        ))),
    }
}

fn consume_token_ignore_new_lines<'a>(
    expected: &Token,
    source_token_details: &'a [TokenDetail],
) -> Result<&'a [TokenDetail], Error> {
    let token_details = skip_new_lines(source_token_details);
    consume_token(expected, token_details)
}

fn consume_new_line_token_if_exists(
    source_token_details: &[TokenDetail],
) -> Result<&[TokenDetail], Error> {
    match source_token_details.split_first() {
        Some((first, rest)) => {
            if first.token == Token::NewLine {
                Ok(rest)
            } else {
                Err(Error::ParserError(
                    "expected the new-line symbol".to_string(),
                ))
            }
        }
        None => Ok(source_token_details),
    }
}

fn new_range() -> Range {
    // todo::
    // å„æˆå‘˜çš„å€¼åº”è¯¥æœ‰å‚æ•°ä¼ å…¥
    Range {
        file_id: 0,
        start: 0,
        end: 0,
    }
}

#[cfg(test)]
mod tests {
    use crate::{
        ast::{
            BinaryExpression, BlockExpression, Complex, Ellipsis, Expression, Float, Identifier,
            Integer, Interval, List, Literal, Node, PrefixIdentifier, Program, Statement, Tuple,
        },
        error::Error,
        lexer,
        parser::new_range,
        token::Token,
    };

    use super::parse;

    // è¾…åŠ©å‡½æ•°

    fn parse_from_string(text: &str) -> Result<Node, Error> {
        let token_details = lexer::tokenize(text)?;
        parse(&token_details)
    }

    fn trim_left_margin(s: &str) -> String {
        s.split("\n")
            .map(|s| s.trim_start().to_string())
            .collect::<Vec<String>>()
            .join("\n")
    }

    // literal

    #[test]
    fn test_integer_literal() {
        let n1 = parse_from_string("123").unwrap();
        assert_eq!(
            n1,
            Node::Program(Program {
                body: vec![Statement::Expression(Expression::Literal(
                    Literal::Integer(Integer {
                        value: 123,
                        range: new_range()
                    })
                ))],
                range: new_range()
            })
        );

        assert_eq!(n1.to_string(), "123\n"); // Statement ä»¥ç¬¦å· '\n' ç»“å°¾
    }

    #[test]
    fn test_float_literal() {
        let n1 = parse_from_string("3.14").unwrap();
        assert_eq!(n1.to_string(), "3.14\n");

        let n2 = parse_from_string("3.14e2").unwrap();
        assert_eq!(n2.to_string(), "314\n");

        let n3 = parse_from_string("3.14e-1").unwrap();
        assert_eq!(n3.to_string(), "0.314\n");
    }

    #[test]
    fn test_complex_literal() {
        let n1 = parse_from_string("3+4i").unwrap();
        assert_eq!(n1.to_string(), "3+4i\n");

        let n2 = parse_from_string("0+2i").unwrap();
        assert_eq!(n2.to_string(), "0+2i\n");

        let n3 = parse_from_string("5i").unwrap();
        assert_eq!(n3.to_string(), "0+5i\n");

        let n4 = parse_from_string("1.414+2.718i").unwrap();
        assert_eq!(n4.to_string(), "1.414+2.718i\n");

        let n5 = parse_from_string("3.14i").unwrap();
        assert_eq!(n5.to_string(), "0+3.14i\n");

        let n6 = parse_from_string("3.14e2i").unwrap();
        assert_eq!(n6.to_string(), "0+314i\n");

        let n7 = parse_from_string("3.14e-1i").unwrap();
        assert_eq!(n7.to_string(), "0+0.314i\n");
    }

    #[test]
    fn test_bit_literal() {
        // todo::
        // let n1 = parse_from_string("16'x08cd").unwrap();
        // assert_eq!(n1.to_string(), "16'x08cd\n");
        //
        // let n2 = parse_from_string("8'b10000001").unwrap();
        // assert_eq!(n2.to_string(), "8'x81\n");
    }

    #[test]
    fn test_boolean_literal() {
        let n1 = parse_from_string("true").unwrap();
        assert_eq!(n1.to_string(), "true\n");

        let n2 = parse_from_string("false").unwrap();
        assert_eq!(n2.to_string(), "false\n");
    }

    #[test]
    fn test_char_literal() {
        let n1 = parse_from_string("'a'").unwrap();
        assert_eq!(n1.to_string(), "'a'\n");

        let n2 = parse_from_string("'æ–‡'").unwrap();
        assert_eq!(n2.to_string(), "'æ–‡'\n");

        // todo:: æµ‹è¯•è½¬ä¹‰å­—ç¬¦ï¼Œè½¬ä¹‰å¸Œè…Šå­—ç¬¦
        // todo:: æµ‹è¯• Unicode
    }

    #[test]
    fn test_general_string_literal() {
        let n1 = parse_from_string("\"abc\"").unwrap();
        assert_eq!(n1.to_string(), "\"abc\"\n");

        let n2 = parse_from_string("\"ä¸­æ–‡ğŸ±\"").unwrap();
        assert_eq!(n2.to_string(), "\"ä¸­æ–‡ğŸ±\"\n");

        // æµ‹è¯•å¤šè¡Œæ–‡æœ¬
        let n3 = parse_from_string("\"foo\nbar\n  baz\"").unwrap();
        assert_eq!(n3.to_string(), "\"foo\nbar\n  baz\"\n");

        // todo:: æµ‹è¯•è½¬ä¹‰å­—ç¬¦
    }

    #[test]
    fn test_template_string_literal() {
        // todo::
    }

    #[test]
    fn test_hash_string_literal() {
        let n1 = parse_from_string("#abc").unwrap();
        assert_eq!(n1.to_string(), "#abc\n");

        let n2 = parse_from_string("#foo_bar").unwrap();
        assert_eq!(n2.to_string(), "#foo_bar\n");

        // todo:: æ·»åŠ ä¸­æ–‡çš„æ”¯æŒ
        // let n3 = parse_from_string("#ä¸­æ–‡ğŸ±").unwrap();
        // assert_eq!(n3.to_string(), "#ä¸­æ–‡ğŸ±\n");
    }

    #[test]
    fn test_named_operator_string_literal() {
        let n1 = parse_from_string(":abc:").unwrap();
        assert_eq!(n1.to_string(), ":abc:\n");

        let n2 = parse_from_string(":foo_bar:").unwrap();
        assert_eq!(n2.to_string(), ":foo_bar:\n");

        // todo:: æ·»åŠ ä¸­æ–‡çš„æ”¯æŒ
        // let n3 = parse_from_string(":ä¸­æ–‡ğŸ±:").unwrap();
        // assert_eq!(n3.to_string(), ":ä¸­æ–‡ğŸ±:\n");
    }

    // primary expressions

    #[test]
    fn test_prefix_identifier() {
        let n1 = parse_from_string("!foo").unwrap();
        assert_eq!(n1.to_string(), "!foo\n");

        let n2 = parse_from_string("!foo::bar").unwrap();
        assert_eq!(n2.to_string(), "!foo::bar\n");
    }

    #[test]
    fn test_tuple() {
        let n1 = parse_from_string("(123,)").unwrap(); // æ‹¬å·å†…çš„é€—å·ä¸èƒ½çœç•¥
        assert_eq!(n1.to_string(), "(123,)\n");

        // å¤šä¸ªå…ƒç´ 
        let n2 = parse_from_string("(123,1.732)").unwrap();
        assert_eq!(n2.to_string(), "(123, 1.732,)\n");

        // å…ƒç´ åˆ—è¡¨ä»¥é€—å·ç»“å°¾
        let n3 = parse_from_string("(123,1.732,)").unwrap();
        assert_eq!(n3.to_string(), "(123, 1.732,)\n");

        // ç©ºå…ƒç»„
        let n4 = parse_from_string("()").unwrap();
        assert_eq!(n4.to_string(), "()\n");

        // å¸¦æœ‰çœç•¥å·å…ƒç´ çš„å…ƒç»„
        let n5 = parse_from_string("(123,...)").unwrap();
        assert_eq!(n5.to_string(), "(123, ...,)\n");

        // å¸¦æœ‰çœç•¥å·æ ‡è¯†ç¬¦å…ƒç´ çš„å…ƒç»„
        let n6 = parse_from_string("(123,...abc)").unwrap();
        assert_eq!(n6.to_string(), "(123, ...abc,)\n");

        // é€—å·ç»“å°¾
        let n7 = parse_from_string("(123,...abc,)").unwrap();
        assert_eq!(n7.to_string(), "(123, ...abc,)\n");
    }

    #[test]
    fn test_list() {
        let n1 = parse_from_string("[123]").unwrap();
        assert_eq!(n1.to_string(), "[123,]\n");

        // å…ƒç´ åˆ—è¡¨ä»¥ `é€—å·` ç»“å°¾
        let n2 = parse_from_string("[123,]").unwrap();
        assert_eq!(n2.to_string(), "[123,]\n");

        // å¤šä¸ªå…ƒç´ 
        let n3 = parse_from_string("[123,1.732]").unwrap();
        assert_eq!(n3.to_string(), "[123, 1.732,]\n");

        // å…ƒç´ åˆ—è¡¨ä»¥é€—å·ç»“å°¾
        let n4 = parse_from_string("[123,1.732,]").unwrap();
        assert_eq!(n4.to_string(), "[123, 1.732,]\n");

        // ç©ºåˆ—è¡¨
        let n5 = parse_from_string("[]").unwrap();
        assert_eq!(n5.to_string(), "[]\n");

        // å¸¦æœ‰çœç•¥å·å…ƒç´ çš„åˆ—è¡¨
        let n6 = parse_from_string("[123,...]").unwrap();
        assert_eq!(n6.to_string(), "[123, ...,]\n");

        // å¸¦æœ‰çœç•¥å·æ ‡è¯†ç¬¦å…ƒç´ çš„åˆ—è¡¨
        let n7 = parse_from_string("[123,...abc]").unwrap();
        assert_eq!(n7.to_string(), "[123, ...abc,]\n");

        // é€—å·ç»“å°¾
        let n8 = parse_from_string("[123,...abc,]").unwrap();
        assert_eq!(n8.to_string(), "[123, ...abc,]\n");

        // èŒƒå›´è¡¨è¾¾å¼çš„åˆ—è¡¨
        let n9 = parse_from_string("[1..10]").unwrap();
        assert_eq!(n9.to_string(), "[1..10,]\n");

        // é€—å·ç»“å°¾
        let n10 = parse_from_string("[1..10,]").unwrap();
        assert_eq!(n10.to_string(), "[1..10,]\n");

        // "çœç•¥äº†èŒƒå›´ç»“æŸå€¼çš„èŒƒå›´è¡¨è¾¾å¼" çš„åˆ—è¡¨
        let n11 = parse_from_string("[1..]").unwrap();
        assert_eq!(n11.to_string(), "[1..,]\n");

        // é€—å·ç»“å°¾
        let n12 = parse_from_string("[1..,]").unwrap();
        assert_eq!(n12.to_string(), "[1..,]\n");

        // ä¸€ä¸ªå…ƒç´ ï¼Œä»¥åŠä¸€ä¸ªèŒƒå›´è¡¨è¾¾å¼çš„åˆ—è¡¨
        let n13 = parse_from_string("[1,3..10]").unwrap();
        assert_eq!(n13.to_string(), "[1, 3..10,]\n");

        // ä¸€ä¸ªå…ƒç´ ï¼Œä»¥åŠä¸€ä¸ªçœç•¥äº†ç»“æŸå€¼çš„èŒƒå›´è¡¨è¾¾å¼çš„åˆ—è¡¨
        let n14 = parse_from_string("[1,3..]").unwrap();
        assert_eq!(n14.to_string(), "[1, 3..,]\n");

        // é—­åŒºé—´
        let n15 = parse_from_string("[1..=10]").unwrap();
        assert_eq!(n15.to_string(), "[1..=10,]\n");

        // ä¸€ä¸ªå…ƒç´ ï¼Œä»¥åŠä¸€ä¸ªé—­åŒºé—´èŒƒå›´è¡¨è¾¾å¼çš„åˆ—è¡¨
        let n16 = parse_from_string("[1,3..=9]").unwrap();
        assert_eq!(n16.to_string(), "[1, 3..=9,]\n");
    }

    #[test]
    fn test_map() {
        //
    }

    #[test]
    fn test_identifier() {
        let n1 = parse_from_string("foo").unwrap();
        assert_eq!(
            n1,
            Node::Program(Program {
                body: vec![Statement::Expression(Expression::Identifier(Identifier {
                    dirs: vec![],
                    name: "foo".to_string(),
                    generic_names: vec![],
                    range: new_range()
                }))],
                range: new_range()
            })
        );
        assert_eq!(n1.to_string(), "foo\n");

        let n2 = parse_from_string("foo::bar").unwrap();
        assert_eq!(n2.to_string(), "foo::bar\n");

        let n3 = parse_from_string("foo::bar::baz").unwrap();
        assert_eq!(n3.to_string(), "foo::bar::baz\n");
    }

    #[test]
    fn test_sign() {
        //
    }

    #[test]
    fn test_anonymous_function() {
        //
    }

    // operating expressions

    #[test]
    fn test_slice_expression() {
        //
    }

    #[test]
    fn test_member_expression() {
        //
    }

    #[test]
    fn test_constructor_expression() {
        //
    }

    #[test]
    fn test_function_call_expression() {
        //
    }

    #[test]
    fn test_unary_expression() {
        //
    }

    #[test]
    fn test_binary_expression_additive() {
        let n1 = parse_from_string("1+2").unwrap();
        assert_eq!(
            n1,
            Node::Program(Program {
                body: vec![Statement::Expression(Expression::BinaryExpression(
                    BinaryExpression {
                        operator: Token::Plus,
                        left: Box::new(Expression::Literal(Literal::Integer(Integer {
                            value: 1,
                            range: new_range()
                        }))),
                        right: Box::new(Expression::Literal(Literal::Integer(Integer {
                            value: 2,
                            range: new_range()
                        }))),
                        range: new_range()
                    }
                ))],
                range: new_range()
            })
        );
        assert_eq!(n1.to_string(), "(1 + 2)\n"); // Statement ä»¥ç¬¦å· '\n' ç»“å°¾

        let n2 = parse_from_string("1+2+3").unwrap();
        assert_eq!(n2.to_string(), "((1 + 2) + 3)\n");

        let n3 = parse_from_string("1.414+1.732").unwrap();
        assert_eq!(n3.to_string(), "(1.414 + 1.732)\n");

        // æµ‹è¯•å¤æ•°å’ŒåŠ æ³•å¹¶å­˜çš„æƒ…å†µ
        let n4 = parse_from_string("3+4i+9i").unwrap();
        assert_eq!(n4.to_string(), "(3+4i + 0+9i)\n");
    }

    #[test]
    fn test_binary_expression_precedence() {
        let n1 = parse_from_string("1|2||3").unwrap();
        assert_eq!(n1.to_string(), "(1 | (2 || 3))\n");

        let n2 = parse_from_string("1||2&&3").unwrap();
        assert_eq!(n2.to_string(), "(1 || (2 && 3))\n");

        let n3 = parse_from_string("1&&2==3").unwrap();
        assert_eq!(n3.to_string(), "(1 && (2 == 3))\n");

        let n4 = parse_from_string("1==2>3").unwrap();
        assert_eq!(n4.to_string(), "(1 == (2 > 3))\n");

        let n5 = parse_from_string("1>2:bit_or:3").unwrap();
        assert_eq!(n5.to_string(), "(1 > (2 :bit_or: 3))\n");

        let n6 = parse_from_string("1:bit_and:2++3").unwrap();
        assert_eq!(n6.to_string(), "(1 :bit_and: (2 ++ 3))\n");

        let n7 = parse_from_string("1++2+3").unwrap();
        assert_eq!(n7.to_string(), "(1 ++ (2 + 3))\n");

        let n8 = parse_from_string("1+2*3").unwrap();
        assert_eq!(n8.to_string(), "(1 + (2 * 3))\n");

        let n9 = parse_from_string("1*2??3").unwrap();
        assert_eq!(n9.to_string(), "(1 * (2 ?? 3))\n");

        let n10 = parse_from_string("1??2>>3").unwrap();
        assert_eq!(n10.to_string(), "(1 ?? (2 >> 3))\n");

        let n11 = parse_from_string("1>>2&3").unwrap();
        assert_eq!(n11.to_string(), "(1 >> (2 & 3))\n");
    }

    #[test]
    fn test_binary_expression_parenthesized() {
        let n1 = parse_from_string("(123)").unwrap();
        assert_eq!(
            n1,
            Node::Program(Program {
                body: vec![Statement::Expression(Expression::Literal(
                    Literal::Integer(Integer {
                        value: 123,
                        range: new_range()
                    })
                ))],
                range: new_range()
            })
        );
        assert_eq!(n1.to_string(), "123\n");

        let n2 = parse_from_string("(1+2)").unwrap();
        assert_eq!(n2.to_string(), "(1 + 2)\n");

        let n3 = parse_from_string("(1+2)*3").unwrap();
        assert_eq!(n3.to_string(), "((1 + 2) * 3)\n");
    }

    #[test]
    fn test_binary_expression_associativitye() {
        // æµ‹è¯•ç»“åˆæ–¹å‘

        // æ“ä½œç¬¦ `+` ä»å·¦å‘å³ç»“åˆ
        let n1 = parse_from_string("1+2+3").unwrap();
        assert_eq!(n1.to_string(), "((1 + 2) + 3)\n");

        // æ“ä½œç¬¦ `&` ä»å³å‘å·¦ç»“åˆ
        let n2 = parse_from_string("1&2&3").unwrap();
        assert_eq!(n2.to_string(), "(1 & (2 & 3))\n");
    }

    // genernal expression

    #[test]
    fn test_do_expression() {
        let n1 = parse_from_string(
            "do {
                123
                abc
            }",
        )
        .unwrap();
        assert_eq!(
            n1,
            Node::Program(Program {
                body: vec![Statement::Expression(Expression::BlockExpression(
                    BlockExpression {
                        is_explicit: true,
                        body: vec![
                            Expression::Literal(Literal::Integer(Integer {
                                value: 123,
                                range: new_range()
                            })),
                            Expression::Identifier(Identifier {
                                dirs: vec![],
                                name: "abc".to_string(),
                                generic_names: vec![],
                                range: new_range()
                            }),
                        ],
                        range: new_range()
                    }
                ))],
                range: new_range()
            })
        );

        assert_eq!(
            n1.to_string(),
            trim_left_margin(
                "do {
                    123
                    abc
                }\n"
            )
        );
    }

    #[test]
    fn test_let_expression() {
        // todo::
    }

    #[test]
    fn test_join_expression() {
        // todo::
    }

    #[test]
    fn test_if_expression() {
        // todo::
    }

    #[test]
    fn test_for_expression() {
        // todo::
    }

    #[test]
    fn test_each_expression() {
        // todo::
    }

    #[test]
    fn test_branch_expression() {
        // todo::
    }

    #[test]
    fn test_match_expression() {
        // todo::
    }

    // statements

    #[test]
    fn test_function_declaration_statement() {
        // todo::
    }
}
